
// This file is auto-generated by `genkit-cli`.
// Do not edit this file directly.
// To regenerate this file, run `genkit-cli dev`.

import {
  Path,
  Accept,
  handleRequest,
  UnsupportedPathError,
  Cors,
} from '@genkit-ai/next';
import { defineFlow, __getFlows } from 'genkit/flow';
import {lookupAction} from 'genkit/action';
import {lookupFlow} from 'genkit/flow';
import {
  assertDotprompt,
  defineDotprompt,
  loadDotprompt,
} from 'genkit/dotprompt';
import {
  type Flow,
  type FlowInputSchema,
  type FlowOutputSchema,
  type FlowStream,
  type FlowStreamChunk,
} from 'genkit/flow';

import * as summarizeTranscriptFlow from '@/ai/flows/summarize-transcript';
import * as conceptExtractionAgentFlow from '@/ai/agents/conceptExtractionAgent';
import * as brahmaChatFlow from '@/ai/flows/brahmaChatFlow';
import * as handleMessageFeedbackFlow from '@/ai/flows/feedbackFlow';
import * as debateFlow from '@/ai/flows/debateFlow';
import * as suggestionGenerationFlow from '@/ai/flows/suggestionGenerationFlow';
import * as textToSpeechFlow from '@/ai/flows/textToSpeechFlow';

const summarizeTranscriptPrompt = defineDotprompt(
  {
    name: 'summarizeTranscriptPrompt',
    model: 'googleai/gemini-2.0-flash',
    input: {
      schema: summarizeTranscriptFlow.SummarizeTranscriptInputSchema,
    },
    output: {
      schema: summarizeTranscriptFlow.SummarizeTranscriptOutputSchema,
    },
    prompt:
      'Summarize the following transcript concisely, capturing the main points. If the transcript is very short, generic, or seems like placeholder text, state that a detailed summary cannot be generated from it.\n\nTranscript:\n{{transcript}}',
  },
  'framework'
);

const ontologyBuilderPrompt = defineDotprompt(
  {
    name: 'ontologyBuilderPrompt',
    model: 'googleai/gemini-2.0-flash',
    input: {
      schema: z.object({
        fileContentHint: z
          .string()
          .describe('A snippet of text content to base the graph on.'),
      }),
    },
    output: {
      schema: z.object({
        summary: z
          .string()
          .describe(
            'A high-level, one-paragraph summary of the entire text content.'
          ),
        nodes: z
          .array(
            z.object({
              id: z
                .string()
                .describe(
                  "A unique, machine-readable ID for the node (e.g., 'concept_blockchain')."
                ),
              label: z
                .string()
                .describe(
                  "The human-readable name of the node (e.g., 'Blockchain')."
                ),
              type: z
                .enum([
                  'Concept',
                  'Entity',
                  'Emotion',
                  'Topic',
                  'Action',
                ])
                .describe('The type of the node.'),
              description: z
                .string()
                .optional()
                .describe('A brief definition of the node.'),
              metadata: z
                .record(z.any())
                .optional()
                .describe(
                  'Additional metadata, e.g., for entities: category (PERSON, ORG, LOC).'
                ),
            })
          )
          .describe(
            'A list of identified nodes for the knowledge graph.'
          ),
        edges: z
          .array(
            z.object({
              source: z.string().describe('The ID of the source node.'),
              target: z.string().describe('The ID of the target node.'),
              relationship: z
                .enum([
                  'is-a',
                  'part-of',
                  'causes',
                  'enables',
                  'related-to',
                  'antonym-of',
                  'seen-in',
                  'feels-like',
                  'explains',
                  'used-for',
                ])
                .describe(
                  'The type of relationship between the nodes.'
                ),
              description: z
                .string()
                .optional()
                .describe(
                  'A brief description of how the nodes are related.'
                ),
              weight: z
                .number()
                .optional()
                .describe('The strength of the connection (0-1).'),
            })
          )
          .describe(
            'A list of inferred edges connecting the nodes in the knowledge graph.'
          ),
      }),
    },
    prompt:
      "You are an advanced AI assistant acting as an Ontology Builder. Your task is to analyze the following text and construct a knowledge graph from it.\n\nText to Analyze:\n'''\n{{fileContentHint}}\n'''\n\nBased *only* on the provided text, perform the following actions:\n1.  **Summary**: Write a concise, one-paragraph summary of the text.\n2.  **Nodes**: Identify the key concepts, entities, topics, and actions. Create a 'GraphNode' for each.\n    *   Use clear, machine-readable IDs (e.g., 'concept_distributed_ledger').\n    *   Assign a relevant type: 'Concept', 'Entity', 'Topic', 'Action', 'Emotion'.\n3.  **Edges**: This is the most critical step. Infer the relationships between the nodes you identified. Create a 'GraphEdge' for each connection.\n    *   Use relationship types like 'is-a', 'part-of', 'causes', 'enables', 'related-to', 'antonym-of', 'seen-in', 'feels-like', 'explains', 'used-for'.\n    *   Infer at least 2-5 meaningful relationships from the text.\n\nEnsure your output strictly adheres to the schema. If the text is unsupported or too short to analyze, return an empty array for nodes and edges.\n",
  },
  'framework'
);

const intentAndEmotionPrompt = defineDotprompt(
  {
    name: 'intentAndEmotionPrompt',
    model: 'googleai/gemini-2.0-flash',
    input: {
      schema: z.object({ userQuery: z.string() }),
    },
    output: {
      schema: z.object({
        intent: z
          .string()
          .describe(
            "The user's primary goal (e.g., 'ask_question', 'request_action', 'provide_feedback', 'casual_conversation')."
          ),
        emotion: z
          .string()
          .describe(
            "The dominant emotional tone of the user's message (e.g., 'curious', 'frustrated', 'excited', 'neutral', 'confused')."
          ),
      }),
    },
    prompt:
      'Analyze the following user query and classify its intent and emotional tone.\nUser Query: "{{userQuery}}"',
  },
  'framework'
);

const brahmaReasoningPrompt = defineDotprompt(
  {
    name: 'brahmaReasoningPrompt',
    model: 'googleai/gemini-2.0-flash',
    input: {
      schema: z.object({
        userQuery: z.string(),
        intent: z.string(),
        emotion: z.string(),
        documentContext: z.string().nullable().optional(),
        chatHistory: z
          .array(
            z.object({
              sender: z.enum(['user', 'ai']),
              text: z.string(),
            })
          )
          .optional(),
        knowledgeGraph: z.any().nullable().optional(),
      }),
    },
    output: {
      schema: z.object({
        reasoningTrace: z
          .string()
          .describe(
            "The full chain of 'Thought -> Action -> Observation -> Reflection' that led to the final answer. This is your internal monologue."
          ),
        finalResponse: z
          .string()
          .describe(
            "The final, synthesized, user-facing response, which has been checked by your internal Moral Compass and adapted to the user's personality."
          ),
        confidenceScore: z
          .number()
          .min(0)
          .max(1)
          .describe(
            'A score from 0.0 to 1.0 indicating confidence in the quality and appropriateness of the final response.'
          ),
        synthesisLog: z
          .string()
          .describe(
            'A brief justification for why the response is good and how the different reasoning steps were integrated.'
          ),
      }),
    },
    prompt:
      "The user's query is: \"{{userQuery}}\"\n- Detected Intent: {{intent}}\n- Detected Emotion: {{emotion}}\n{{#if knowledgeGraph}}\n- **Knowledge Graph Context (Primary Memory Source):** {{{knowledgeGraph.summary}}}\n  - This knowledge graph also contains detailed nodes and relationships about concepts relevant to the user's uploaded document. Refer to these concepts when forming your answer.\n{{else if documentContext}}\n- Document Context (Legacy): {{{documentContext}}}\n{{/if}}\nChat History:\n{{#each chatHistory}}\n  {{this.sender}}: {{this.text}}\n{{/each}}\n\nBegin your thought process now. Remember to output a single JSON object when you are finished.",
  },
  'framework'
);

const suggestionPrompt = defineDotprompt(
  {
    name: 'suggestionPrompt',
    model: 'googleai/gemini-2.0-flash',
    input: {
      schema: suggestionGenerationFlow.SuggestionGenerationInputSchema,
    },
    output: {
      schema: suggestionGenerationFlow.SuggestionGenerationOutputSchema,
    },
    prompt:
      'You are a helpful AI assistant. A user has just finished a conversation with the title: "{{lastSessionTitle}}".\n\nYour task is to generate exactly three distinct, thought-provoking, and open-ended follow-up prompts to re-engage the user. Each prompt needs a short \'title\' or category label. The suggestions should be short (under 15 words) and encourage deeper thinking, creativity, or reflection related to the previous topic.\n\nDo not be generic. Base your suggestions directly on the "{{lastSessionTitle}}".\n\nExample:\nIf the last session title was "Brainstorming a marketing plan for a new coffee shop", a good response would be:\n{\n  "suggestions": [\n    { "title": "Unconventional Idea", "prompt": "What\'s one wild marketing idea we didn\'t explore?" },\n    { "title": "Launch Event", "prompt": "How could we make the launch event unforgettable?" },\n    { "title": "Ideal Customer", "prompt": "Let\'s imagine the coffee shop\'s biggest fan. What are they like?" }\n  ]\n}\n\nGenerate three suggestions now.',
  },
  'framework'
);

const allDotprompts = {
  summarizeTranscriptPrompt: summarizeTranscriptPrompt,
  ontologyBuilderPrompt: ontologyBuilderPrompt,
  intentAndEmotionPrompt: intentAndEmotionPrompt,
  brahmaReasoningPrompt: brahmaReasoningPrompt,
  suggestionPrompt: suggestionPrompt,
};

export async function GET(req: Request) {
  const G = global as any;
  if (!G.genkitTools) {
    G.genkitTools = {
      prompts: {
        list: () => Object.keys(allDotprompts),
        get: (name: string) => allDotprompts[name],
      },
    };
  }
  return handleRequest({
    req,
    path: Path.GET,
    cors: Cors.fromEnv(),
    lookupAction,
    lookupFlow,
    __getFlows,
  });
}

export async function POST(req: Request) {
  return handleRequest({
    req,
    path: Path.POST,
    cors: Cors.fromEnv(),
    lookupAction,
    lookupFlow,
    __getFlows,
  });
}

export async function OPTIONS(req: Request) {
  return handleRequest({
    req,
    path: Path.OPTIONS,
    cors: Cors.fromEnv(),
    lookupAction,
    lookupFlow,
    __getFlows,
  });
}
